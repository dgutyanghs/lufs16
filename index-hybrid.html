<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è§†é¢‘éŸ³é¢‘å“åº¦è°ƒèŠ‚å™¨ (æ··åˆç‰ˆæœ¬)</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }

        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        .upload-area {
            border: 2px dashed #ccc;
            border-radius: 10px;
            padding: 40px;
            text-align: center;
            margin-bottom: 20px;
            transition: border-color 0.3s;
        }

        .upload-area:hover {
            border-color: #007bff;
        }

        .upload-area.dragover {
            border-color: #007bff;
            background-color: #f0f8ff;
        }

        input[type="file"] {
            display: none;
        }

        .btn {
            background-color: #007bff;
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            margin: 5px;
        }

        .btn:hover {
            background-color: #0056b3;
        }

        .btn:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }

        .progress {
            width: 100%;
            height: 20px;
            background-color: #f0f0f0;
            border-radius: 10px;
            overflow: hidden;
            margin: 10px 0;
        }

        .progress-bar {
            height: 100%;
            background-color: #007bff;
            width: 0%;
            transition: width 0.3s;
        }

        .info-panel {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }

        .hidden {
            display: none;
        }

        .warning {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            color: #856404;
        }

        .success {
            background-color: #d4edda;
            border: 1px solid #c3e6cb;
            color: #155724;
        }

        .feature-comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
            margin: 20px 0;
        }

        .feature-card {
            padding: 15px;
            border-radius: 8px;
            border: 1px solid #ddd;
        }

        .feature-card h4 {
            margin-top: 0;
            color: #333;
        }

        .feature-list {
            list-style: none;
            padding: 0;
        }

        .feature-list li {
            padding: 5px 0;
            border-bottom: 1px solid #eee;
        }

        .feature-list li:before {
            content: "âœ… ";
            color: #28a745;
        }

        .limitation:before {
            content: "âš ï¸ ";
            color: #ffc107;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>è§†é¢‘éŸ³é¢‘å“åº¦è°ƒèŠ‚å™¨ (æ··åˆç‰ˆæœ¬)</h1>
        <p>ä¸“ä¸šçº§éŸ³é¢‘å“åº¦åˆ†æå’Œè°ƒèŠ‚å·¥å…·ï¼Œç»“åˆWeb Audio APIå’ŒMediaRecorderæŠ€æœ¯</p>

        <div id="versionInfo" class="info-panel warning">
            <h3>ğŸ”§ æŠ€æœ¯è¯´æ˜</h3>
            <p>ç”±äºFFmpeg.js CDNé—®é¢˜ï¼Œæ­¤ç‰ˆæœ¬ä½¿ç”¨æ··åˆæŠ€æœ¯æ ˆæä¾›ä¸“ä¸šçº§éŸ³é¢‘å¤„ç†åŠŸèƒ½ï¼š</p>
            <div class="feature-comparison">
                <div class="feature-card">
                    <h4>âœ… å¯ç”¨åŠŸèƒ½</h4>
                    <ul class="feature-list">
                        <li>ä¸“ä¸šLUFSå“åº¦åˆ†æ</li>
                        <li>å®æ—¶éŸ³é¢‘å¢ç›Šè°ƒèŠ‚</li>
                        <li>å³°å€¼ç”µå¹³æ£€æµ‹</li>
                        <li>åŠ¨æ€èŒƒå›´åˆ†æ</li>
                        <li>éŸ³é¢‘å¯è§†åŒ–</li>
                        <li>å¤„ç†åéŸ³é¢‘å¯¼å‡º</li>
                    </ul>
                </div>
                <div class="feature-card">
                    <h4>âš ï¸ æŠ€æœ¯é™åˆ¶</h4>
                    <ul class="feature-list">
                        <li class="limitation">è¾“å‡ºä¸ºéŸ³é¢‘æ–‡ä»¶(WAV)</li>
                        <li class="limitation">è§†é¢‘éœ€å•ç‹¬å¤„ç†</li>
                        <li class="limitation">åŸºäºæµè§ˆå™¨éŸ³é¢‘API</li>
                        <li class="limitation">æ–‡ä»¶å¤§å°é™åˆ¶500MB</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="upload-area" id="uploadArea">
            <p>æ‹–æ‹½è§†é¢‘æ–‡ä»¶åˆ°è¿™é‡Œæˆ–ç‚¹å‡»é€‰æ‹©æ–‡ä»¶</p>
            <button class="btn" onclick="document.getElementById('fileInput').click()">é€‰æ‹©è§†é¢‘æ–‡ä»¶</button>
            <input type="file" id="fileInput" accept="video/*,audio/*">
        </div>

        <div id="processingPanel" class="hidden">
            <div class="info-panel">
                <h3>å¤„ç†è¿›åº¦</h3>
                <div class="progress">
                    <div class="progress-bar" id="progressBar"></div>
                </div>
                <p id="statusText">å‡†å¤‡ä¸­...</p>
            </div>

            <div id="audioInfo" class="info-panel hidden">
                <h3>éŸ³é¢‘åˆ†æç»“æœ</h3>
                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px;">
                    <div>
                        <p><strong>å“åº¦åˆ†æ</strong></p>
                        <p>åŸå§‹å“åº¦: <span id="originalLUFS">--</span> LUFS</p>
                        <p>ç›®æ ‡å“åº¦: -16 LUFS</p>
                        <p>å¢ç›Šè°ƒèŠ‚: <span id="gainAdjustment">--</span> dB</p>
                    </div>
                    <div>
                        <p><strong>éŸ³é¢‘å‚æ•°</strong></p>
                        <p>å³°å€¼ç”µå¹³: <span id="peakLevel">--</span> dBFS</p>
                        <p>åŠ¨æ€èŒƒå›´: <span id="dynamicRange">--</span> LU</p>
                        <p>é‡‡æ ·ç‡: <span id="sampleRate">--</span> Hz</p>
                    </div>
                </div>

                <div id="audioVisualization" style="margin-top: 15px;">
                    <canvas id="waveformCanvas" width="600" height="100"
                        style="width: 100%; border: 1px solid #ddd;"></canvas>
                </div>
            </div>
        </div>

        <div id="resultPanel" class="hidden">
            <div class="info-panel success">
                <h3>âœ… å¤„ç†å®Œæˆ</h3>
                <p>éŸ³é¢‘å·²æˆåŠŸè°ƒèŠ‚åˆ° -16 LUFS æ ‡å‡†</p>
            </div>

            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px;">
                <div>
                    <h4>åŸå§‹éŸ³é¢‘</h4>
                    <audio id="originalAudio" controls style="width: 100%;"></audio>
                </div>
                <div>
                    <h4>å¤„ç†åéŸ³é¢‘</h4>
                    <audio id="processedAudio" controls style="width: 100%;"></audio>
                </div>
            </div>

            <div style="text-align: center; margin-top: 20px;">
                <button class="btn" id="downloadBtn">ä¸‹è½½å¤„ç†åçš„éŸ³é¢‘ (WAV)</button>
                <button class="btn" onclick="location.reload()">é‡æ–°å¼€å§‹</button>
            </div>
        </div>
    </div>

    <script>
        // ä¸“ä¸šçº§éŸ³é¢‘å¤„ç†å™¨
        class ProfessionalAudioProcessor {
            constructor() {
                this.audioContext = null;
                this.targetLUFS = -16;
                this.sampleRate = 44100;
            }

            async initAudioContext() {
                if (!this.audioContext) {
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    this.sampleRate = this.audioContext.sampleRate;
                }
                if (this.audioContext.state === 'suspended') {
                    await this.audioContext.resume();
                }
            }

            // ä»è§†é¢‘/éŸ³é¢‘æ–‡ä»¶ä¸­æå–éŸ³é¢‘æ•°æ®
            async extractAudioData(file) {
                await this.initAudioContext();

                const arrayBuffer = await file.arrayBuffer();
                const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);

                return audioBuffer;
            }

            // ä¸“ä¸šçº§LUFSè®¡ç®— (åŸºäºEBU R128æ ‡å‡†çš„ç®€åŒ–ç‰ˆ)
            calculateLUFS(audioBuffer) {
                const channels = audioBuffer.numberOfChannels;
                const length = audioBuffer.length;
                const sampleRate = audioBuffer.sampleRate;

                // è·å–æ‰€æœ‰å£°é“æ•°æ®
                const channelData = [];
                for (let i = 0; i < channels; i++) {
                    channelData.push(audioBuffer.getChannelData(i));
                }

                // åº”ç”¨K-weightingæ»¤æ³¢å™¨ (ç®€åŒ–ç‰ˆ)
                const filteredData = this.applyKWeighting(channelData, sampleRate);

                // è®¡ç®—400mså—çš„å“åº¦
                const blockSize = Math.floor(sampleRate * 0.4); // 400ms
                const hopSize = Math.floor(blockSize * 0.75); // 75% overlap

                let loudnessValues = [];

                for (let start = 0; start < length - blockSize; start += hopSize) {
                    let blockPower = 0;
                    let sampleCount = 0;

                    for (let i = start; i < start + blockSize && i < length; i++) {
                        let sample = 0;

                        // å¤šå£°é“åŠ æƒæ··åˆ
                        for (let ch = 0; ch < channels; ch++) {
                            const weight = channels === 1 ? 1.0 : (ch < 2 ? 1.0 : 0.708); // L/R: 1.0, others: 0.708
                            sample += filteredData[ch][i] * weight;
                        }

                        blockPower += sample * sample;
                        sampleCount++;
                    }

                    if (sampleCount > 0) {
                        const blockLoudness = blockPower / sampleCount;
                        if (blockLoudness > 0) {
                            loudnessValues.push(blockLoudness);
                        }
                    }
                }

                // è®¡ç®—ç§¯åˆ†å“åº¦ (å»é™¤æœ€ä½10%çš„å€¼)
                loudnessValues.sort((a, b) => b - a);
                const validCount = Math.floor(loudnessValues.length * 0.9);
                const validValues = loudnessValues.slice(0, validCount);

                if (validValues.length === 0) return -70;

                const meanSquare = validValues.reduce((sum, val) => sum + val, 0) / validValues.length;
                const lufs = -0.691 + 10 * Math.log10(meanSquare + 1e-12);

                return Math.max(lufs, -70);
            }

            // ç®€åŒ–çš„K-weightingæ»¤æ³¢å™¨
            applyKWeighting(channelData, sampleRate) {
                const filtered = [];

                for (let ch = 0; ch < channelData.length; ch++) {
                    const input = channelData[ch];
                    const output = new Float32Array(input.length);

                    // ç®€åŒ–çš„é«˜é€šæ»¤æ³¢å™¨ (æ¨¡æ‹ŸK-weightingçš„é«˜é¢‘ç‰¹æ€§)
                    let prev = 0;
                    const alpha = 0.95; // é«˜é€šæ»¤æ³¢å™¨ç³»æ•°

                    for (let i = 0; i < input.length; i++) {
                        output[i] = alpha * (output[i - 1] || 0) + alpha * (input[i] - prev);
                        prev = input[i];
                    }

                    filtered.push(output);
                }

                return filtered;
            }

            // è®¡ç®—å³°å€¼ç”µå¹³
            calculatePeakLevel(audioBuffer) {
                let maxPeak = 0;

                for (let ch = 0; ch < audioBuffer.numberOfChannels; ch++) {
                    const channelData = audioBuffer.getChannelData(ch);
                    for (let i = 0; i < channelData.length; i++) {
                        maxPeak = Math.max(maxPeak, Math.abs(channelData[i]));
                    }
                }

                return maxPeak > 0 ? 20 * Math.log10(maxPeak) : -Infinity;
            }

            // è®¡ç®—åŠ¨æ€èŒƒå›´ (ç®€åŒ–ç‰ˆLRA)
            calculateDynamicRange(audioBuffer) {
                const channels = audioBuffer.numberOfChannels;
                const length = audioBuffer.length;
                const sampleRate = audioBuffer.sampleRate;

                // è®¡ç®—3ç§’å—çš„å“åº¦
                const blockSize = Math.floor(sampleRate * 3); // 3ç§’
                let loudnessValues = [];

                for (let start = 0; start < length - blockSize; start += blockSize) {
                    let blockPower = 0;
                    let sampleCount = 0;

                    for (let i = start; i < start + blockSize && i < length; i++) {
                        let sample = 0;
                        for (let ch = 0; ch < channels; ch++) {
                            sample += audioBuffer.getChannelData(ch)[i];
                        }
                        sample /= channels;

                        blockPower += sample * sample;
                        sampleCount++;
                    }

                    if (sampleCount > 0) {
                        const blockLoudness = 10 * Math.log10(blockPower / sampleCount + 1e-12);
                        loudnessValues.push(blockLoudness);
                    }
                }

                if (loudnessValues.length < 2) return 0;

                loudnessValues.sort((a, b) => a - b);
                const p95 = loudnessValues[Math.floor(loudnessValues.length * 0.95)];
                const p10 = loudnessValues[Math.floor(loudnessValues.length * 0.10)];

                return Math.max(0, p95 - p10);
            }

            // åº”ç”¨å¢ç›Šåˆ°éŸ³é¢‘ç¼“å†²åŒº
            applyGain(audioBuffer, gainDB) {
                const gainLinear = Math.pow(10, gainDB / 20);
                const channels = audioBuffer.numberOfChannels;

                // åˆ›å»ºæ–°çš„éŸ³é¢‘ç¼“å†²åŒº
                const processedBuffer = this.audioContext.createBuffer(
                    channels,
                    audioBuffer.length,
                    audioBuffer.sampleRate
                );

                for (let ch = 0; ch < channels; ch++) {
                    const inputData = audioBuffer.getChannelData(ch);
                    const outputData = processedBuffer.getChannelData(ch);

                    for (let i = 0; i < inputData.length; i++) {
                        let sample = inputData[i] * gainLinear;

                        // è½¯é™åˆ¶é˜²æ­¢å‰Šæ³¢
                        if (Math.abs(sample) > 0.95) {
                            sample = sample > 0 ? 0.95 * Math.tanh(sample / 0.95) : -0.95 * Math.tanh(-sample / 0.95);
                        }

                        outputData[i] = sample;
                    }
                }

                return processedBuffer;
            }

            // å°†éŸ³é¢‘ç¼“å†²åŒºè½¬æ¢ä¸ºWAVæ ¼å¼
            audioBufferToWav(audioBuffer) {
                const length = audioBuffer.length;
                const channels = audioBuffer.numberOfChannels;
                const sampleRate = audioBuffer.sampleRate;
                const arrayBuffer = new ArrayBuffer(44 + length * channels * 2);
                const view = new DataView(arrayBuffer);

                // WAVæ–‡ä»¶å¤´
                const writeString = (offset, string) => {
                    for (let i = 0; i < string.length; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                };

                writeString(0, 'RIFF');
                view.setUint32(4, 36 + length * channels * 2, true);
                writeString(8, 'WAVE');
                writeString(12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, channels, true);
                view.setUint32(24, sampleRate, true);
                view.setUint32(28, sampleRate * channels * 2, true);
                view.setUint16(32, channels * 2, true);
                view.setUint16(34, 16, true);
                writeString(36, 'data');
                view.setUint32(40, length * channels * 2, true);

                // éŸ³é¢‘æ•°æ®
                let offset = 44;
                for (let i = 0; i < length; i++) {
                    for (let ch = 0; ch < channels; ch++) {
                        const sample = Math.max(-1, Math.min(1, audioBuffer.getChannelData(ch)[i]));
                        view.setInt16(offset, sample * 0x7FFF, true);
                        offset += 2;
                    }
                }

                return new Blob([arrayBuffer], { type: 'audio/wav' });
            }

            // ç»˜åˆ¶æ³¢å½¢
            drawWaveform(audioBuffer, canvas) {
                const ctx = canvas.getContext('2d');
                const width = canvas.width;
                const height = canvas.height;

                ctx.clearRect(0, 0, width, height);
                ctx.fillStyle = '#f0f0f0';
                ctx.fillRect(0, 0, width, height);

                const channelData = audioBuffer.getChannelData(0);
                const step = Math.ceil(channelData.length / width);

                ctx.strokeStyle = '#007bff';
                ctx.lineWidth = 1;
                ctx.beginPath();

                for (let i = 0; i < width; i++) {
                    let min = 1.0;
                    let max = -1.0;

                    for (let j = 0; j < step; j++) {
                        const sample = channelData[i * step + j] || 0;
                        min = Math.min(min, sample);
                        max = Math.max(max, sample);
                    }

                    const y1 = (1 + min) * height / 2;
                    const y2 = (1 + max) * height / 2;

                    if (i === 0) {
                        ctx.moveTo(i, y1);
                    } else {
                        ctx.lineTo(i, y1);
                        ctx.lineTo(i, y2);
                    }
                }

                ctx.stroke();
            }

            // ä¸»å¤„ç†å‡½æ•°
            async processAudio(file, progressCallback) {
                try {
                    progressCallback(10, 'æ­£åœ¨æå–éŸ³é¢‘æ•°æ®...');
                    const audioBuffer = await this.extractAudioData(file);

                    progressCallback(30, 'æ­£åœ¨åˆ†æéŸ³é¢‘å“åº¦...');
                    const originalLUFS = this.calculateLUFS(audioBuffer);

                    progressCallback(50, 'æ­£åœ¨è®¡ç®—éŸ³é¢‘å‚æ•°...');
                    const peakLevel = this.calculatePeakLevel(audioBuffer);
                    const dynamicRange = this.calculateDynamicRange(audioBuffer);

                    progressCallback(70, 'æ­£åœ¨åº”ç”¨å“åº¦è°ƒèŠ‚...');
                    const gainAdjustment = this.targetLUFS - originalLUFS;
                    const processedBuffer = this.applyGain(audioBuffer, gainAdjustment);

                    progressCallback(90, 'æ­£åœ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶...');
                    const processedWav = this.audioBufferToWav(processedBuffer);
                    const originalWav = this.audioBufferToWav(audioBuffer);

                    progressCallback(100, 'å¤„ç†å®Œæˆ!');

                    return {
                        originalLUFS: originalLUFS,
                        gainAdjustment: gainAdjustment,
                        peakLevel: peakLevel,
                        dynamicRange: dynamicRange,
                        sampleRate: audioBuffer.sampleRate,
                        originalAudio: originalWav,
                        processedAudio: processedWav,
                        originalBuffer: audioBuffer,
                        processedBuffer: processedBuffer
                    };

                } catch (error) {
                    throw new Error(`éŸ³é¢‘å¤„ç†å¤±è´¥: ${error.message}`);
                }
            }
        }

        // ä¸»åº”ç”¨ç±»
        class HybridAudioNormalizer {
            constructor() {
                this.audioProcessor = new ProfessionalAudioProcessor();
                this.currentFile = null;
                this.processedAudioBlob = null;
                this.initializeEventListeners();
            }

            initializeEventListeners() {
                const uploadArea = document.getElementById('uploadArea');
                const fileInput = document.getElementById('fileInput');

                // æ–‡ä»¶æ‹–æ‹½å¤„ç†
                uploadArea.addEventListener('dragover', (e) => {
                    e.preventDefault();
                    uploadArea.classList.add('dragover');
                });

                uploadArea.addEventListener('dragleave', () => {
                    uploadArea.classList.remove('dragover');
                });

                uploadArea.addEventListener('drop', (e) => {
                    e.preventDefault();
                    uploadArea.classList.remove('dragover');
                    const files = e.dataTransfer.files;
                    if (files.length > 0) {
                        this.handleFileSelect(files[0]);
                    }
                });

                // æ–‡ä»¶é€‰æ‹©å¤„ç†
                fileInput.addEventListener('change', (e) => {
                    if (e.target.files.length > 0) {
                        this.handleFileSelect(e.target.files[0]);
                    }
                });
            }

            async handleFileSelect(file) {
                // éªŒè¯æ–‡ä»¶ç±»å‹
                if (!file.type.startsWith('video/') && !file.type.startsWith('audio/')) {
                    alert('è¯·é€‰æ‹©è§†é¢‘æˆ–éŸ³é¢‘æ–‡ä»¶');
                    return;
                }

                // æ£€æŸ¥æ–‡ä»¶å¤§å°
                if (file.size > 500 * 1024 * 1024) {
                    alert('æ–‡ä»¶å¤ªå¤§ï¼Œè¯·é€‰æ‹©å°äº500MBçš„æ–‡ä»¶');
                    return;
                }

                this.currentFile = file;
                this.showProcessingPanel();

                try {
                    await this.processAudio();
                } catch (error) {
                    console.error('å¤„ç†é”™è¯¯:', error);
                    alert(`å¤„ç†å¤±è´¥: ${error.message}`);
                    this.resetInterface();
                }
            }

            showProcessingPanel() {
                document.getElementById('processingPanel').classList.remove('hidden');
                document.getElementById('resultPanel').classList.add('hidden');
            }

            updateProgress(percentage, status) {
                const progressBar = document.getElementById('progressBar');
                const statusText = document.getElementById('statusText');

                progressBar.style.width = `${percentage}%`;
                statusText.textContent = status;
            }

            async processAudio() {
                const result = await this.audioProcessor.processAudio(
                    this.currentFile,
                    (progress, status) => this.updateProgress(progress, status)
                );

                // æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯
                this.displayAudioInfo(result);

                // æ˜¾ç¤ºç»“æœ
                this.showResult(result);
            }

            displayAudioInfo(result) {
                const audioInfo = document.getElementById('audioInfo');
                const originalLUFSElement = document.getElementById('originalLUFS');
                const gainAdjustmentElement = document.getElementById('gainAdjustment');
                const peakLevelElement = document.getElementById('peakLevel');
                const dynamicRangeElement = document.getElementById('dynamicRange');
                const sampleRateElement = document.getElementById('sampleRate');

                originalLUFSElement.textContent = result.originalLUFS.toFixed(1);
                gainAdjustmentElement.textContent = result.gainAdjustment > 0 ?
                    `+${result.gainAdjustment.toFixed(1)}` : result.gainAdjustment.toFixed(1);
                peakLevelElement.textContent = result.peakLevel.toFixed(1);
                dynamicRangeElement.textContent = result.dynamicRange.toFixed(1);
                sampleRateElement.textContent = result.sampleRate;

                // ç»˜åˆ¶æ³¢å½¢
                const canvas = document.getElementById('waveformCanvas');
                this.audioProcessor.drawWaveform(result.originalBuffer, canvas);

                audioInfo.classList.remove('hidden');
            }

            showResult(result) {
                const resultPanel = document.getElementById('resultPanel');
                const originalAudio = document.getElementById('originalAudio');
                const processedAudio = document.getElementById('processedAudio');
                const downloadBtn = document.getElementById('downloadBtn');

                // è®¾ç½®éŸ³é¢‘æ’­æ”¾å™¨
                originalAudio.src = URL.createObjectURL(result.originalAudio);
                processedAudio.src = URL.createObjectURL(result.processedAudio);

                // å­˜å‚¨å¤„ç†åçš„éŸ³é¢‘ç”¨äºä¸‹è½½
                this.processedAudioBlob = result.processedAudio;

                // è®¾ç½®ä¸‹è½½åŠŸèƒ½
                downloadBtn.onclick = () => this.downloadProcessedAudio();

                resultPanel.classList.remove('hidden');
            }

            downloadProcessedAudio() {
                if (!this.processedAudioBlob) {
                    alert('æ²¡æœ‰å¯ä¸‹è½½çš„å¤„ç†åéŸ³é¢‘');
                    return;
                }

                // åˆ›å»ºä¸‹è½½é“¾æ¥
                const link = document.createElement('a');
                const fileName = this.currentFile.name.replace(/\.[^/.]+$/, '_normalized.wav');

                const url = URL.createObjectURL(this.processedAudioBlob);
                link.href = url;
                link.download = fileName;

                // è§¦å‘ä¸‹è½½
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);

                // æ¸…ç†URLå¯¹è±¡
                setTimeout(() => URL.revokeObjectURL(url), 1000);
            }

            resetInterface() {
                document.getElementById('processingPanel').classList.add('hidden');
                document.getElementById('resultPanel').classList.add('hidden');
                document.getElementById('audioInfo').classList.add('hidden');
                document.getElementById('progressBar').style.width = '0%';
                document.getElementById('statusText').textContent = 'å‡†å¤‡ä¸­...';

                // æ¸…ç†èµ„æº
                if (this.processedAudioBlob) {
                    URL.revokeObjectURL(this.processedAudioBlob);
                    this.processedAudioBlob = null;
                }

                this.currentFile = null;
            }
        }

        // åˆå§‹åŒ–åº”ç”¨
        document.addEventListener('DOMContentLoaded', () => {
            new HybridAudioNormalizer();
        });

        // é”™è¯¯å¤„ç†
        window.addEventListener('error', (e) => {
            console.error('åº”ç”¨é”™è¯¯:', e.error);
        });
    </script>
</body>

</html>